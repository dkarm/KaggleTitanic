{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to import all the modules used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "import pandas\n",
    "from ggplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to import both the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#load in csv file train data\n",
    "data = pandas.read_csv('train.csv', header = 0)\n",
    "\n",
    "#load in csv file test data\n",
    "data_test = pandas.read_csv('test.csv', header = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory analysis on train data - not to be used when running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
       "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
       "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering Part 1:\n",
    "Change some of the string variables to numerical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "Gender         891 non-null int64\n",
      "Title          891 non-null object\n",
      "Mother         891 non-null int64\n",
      "FamilySize     891 non-null int64\n",
      "Fare2          891 non-null int64\n",
      "AgeFill        891 non-null float64\n",
      "dtypes: float64(3), int64(9), object(6)\n",
      "memory usage: 125.4+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Mother</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Fare2</th>\n",
       "      <th>AgeFill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>8.910000e+02</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>-2.990500e-17</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>0.062851</td>\n",
       "      <td>1.904602</td>\n",
       "      <td>1.527497</td>\n",
       "      <td>29.112424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>1.000562e+00</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>0.242831</td>\n",
       "      <td>1.613459</td>\n",
       "      <td>0.672139</td>\n",
       "      <td>13.304424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.559950e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.536006e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.242883e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.046949e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.374643e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
       "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
       "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch          Fare      Gender      Mother  FamilySize  \\\n",
       "count  891.000000  8.910000e+02  891.000000  891.000000  891.000000   \n",
       "mean     0.381594 -2.990500e-17    0.352413    0.062851    1.904602   \n",
       "std      0.806057  1.000562e+00    0.477990    0.242831    1.613459   \n",
       "min      0.000000 -5.559950e-01    0.000000    0.000000    1.000000   \n",
       "25%      0.000000 -3.536006e-01    0.000000    0.000000    1.000000   \n",
       "50%      0.000000 -3.242883e-01    0.000000    0.000000    1.000000   \n",
       "75%      0.000000  1.046949e-01    1.000000    0.000000    2.000000   \n",
       "max      6.000000  1.374643e+01    1.000000    1.000000   11.000000   \n",
       "\n",
       "            Fare2     AgeFill  \n",
       "count  891.000000  891.000000  \n",
       "mean     1.527497   29.112424  \n",
       "std      0.672139   13.304424  \n",
       "min      1.000000    0.420000  \n",
       "25%      1.000000   21.500000  \n",
       "50%      1.000000   26.000000  \n",
       "75%      2.000000   36.000000  \n",
       "max      3.000000   80.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the Sex variable to Gender\n",
    "data['Gender']=0\n",
    "data['Gender'] = data['Sex'].map( {'female':1, 'male':0}).astype(int)\n",
    "\n",
    "#title\n",
    "\n",
    "\n",
    "\n",
    "data['Title']=data['Name'].str.split(',').str.get(1).str.split().str.get(0)\n",
    "data.loc[(data['Title']=='Mlle.') ,'Title']=\"Miss.\"\n",
    "data.loc[(data['Title']==\"Mme.\") ,'Title']=\"Mrs.\"\n",
    "data.loc[(data['Title']==\"Ms.\") ,'Title']=\"Mrs.\"\n",
    "\n",
    "data['Rare']=data['Title'].isin([\"Master.\", \"Miss.\", \"Mrs.\", \"Mr.\"])\n",
    "\n",
    "data.loc[(data['Rare']==False),'Title']=\"Other\"\n",
    "data = data.drop(['Rare'], axis = 1)\n",
    "\n",
    "data['Mother']=0\n",
    "data.loc[((data['Title']==\"Mrs.\")&(data['Parch']>0)),'Mother']=1\n",
    "\n",
    "#Family Size\n",
    "data['FamilySize']=data['SibSp']+data['Parch']+1\n",
    "\n",
    "#Fare\n",
    "data['Fare']=data['Fare']/data['FamilySize']\n",
    "data['Fare2']=2\n",
    "data.loc[(data['Fare']<10),'Fare2']=1\n",
    "data.loc[(data['Fare']>40),'Fare2']=3\n",
    "\n",
    "\n",
    "\n",
    "#Fill in missing ages with the Median and call AgeFill\n",
    "data['AgeFill']=data['Age']\n",
    "median_ages = np.zeros((2,3))\n",
    "\n",
    "#fill in median of master for those with missing values \n",
    "data.loc[(data['Title']=='Master')& (data.Age.isnull()),'AgeFill']=data[data['Title']=='Master']['Age'].dropna().median()\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_ages[i,j] = data[(data['Gender'] == i ) & (data['Pclass'] ==j+1)]['Age'].dropna().median()\n",
    "\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata.loc[ (data.Age.isnull() & (data['Gender']==i) & (data['Pclass']==j+1)), 'AgeFill']=median_ages[i,j]\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "#Normalize data for fare\n",
    "from sklearn.preprocessing import scale\n",
    "data['Fare']=scale(data['Fare'])        \n",
    "\n",
    "#Embarked\n",
    "data['Embarked']=data['Embarked'].fillna(\"S\")\n",
    "data['Embarked'][data['Embarked']==\"S\"]=0\n",
    "data['Embarked'][data['Embarked']==\"C\"]=1\n",
    "data['Embarked'][data['Embarked']==\"Q\"]=2\n",
    "#data['Embarked']=data['Embarked'].astype(int)\n",
    "\n",
    "\n",
    "#Ticket\n",
    "#data['Tix']=data['Ticket'].str.split().str.get(0)\n",
    "\n",
    "\n",
    "\n",
    "#print data['Ticket'].str.split().head(10)\n",
    "\n",
    "\n",
    "\n",
    "print data.info()\n",
    "\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create new variables for family name and create a variable that predicts whether the family survived or not \n",
    "#clued in as 1 if anyone from the family died\n",
    "\n",
    "\n",
    "#create a Last Name column of data\n",
    "#data['LastName']=data['Name'].str.split(',').str.get(0)\n",
    "\n",
    "\n",
    "\n",
    "####if \"master, then guess young age for boy\n",
    "\n",
    "\n",
    "#data['Title']=le_name.fit_transform(data['Title'])\n",
    "\n",
    "#pandas.crosstab(data['Survived'], data['Title']).transpose()\n",
    "\n",
    "#classify survival by family type\n",
    "#pandas.crosstab(data['Survived'], data['LastName']).transpose()\n",
    "\n",
    "#family_died = np.zeros((2,len(data['LastName'])))\n",
    "\n",
    "#for i in range(0,len(data['LastName'])):\n",
    " #   family_died[0,i]=data[(data['LastName']==i)]['Survived'].sum()\n",
    "\n",
    "#for i in range(0,len(data['LastName'])):\n",
    " #   if family_died[0,i]==0:\n",
    "  #      family_died[1,i]=1\n",
    "\n",
    "#print family_died.transpose()[10]\n",
    "#pandas.crosstab(data['Survived'], data['LastName']).transpose()\n",
    "\n",
    "#data['FamilyDied']=0\n",
    "#for i in range(0,len(data['LastName'])):\n",
    " #   data.loc[(data['LastName']==i),'FamilyDied']=family_died[1,i]\n",
    "\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Is survival linked to port of embarkment or class?\n",
    "\n",
    "Survival was worst for embarked S and for class 3. These were most likely the poor individuals. The women who perished seem to have come from the 'S' embarkment. \n",
    "\n",
    "Is survival linked to family size?\n",
    "\n",
    "It looks like men were travelling alone or those with larger families both perished more. Women who were travelling alone tended to survive more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering for the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Mr.\n",
      "1       Mrs.\n",
      "2      Miss.\n",
      "3       Mrs.\n",
      "4        Mr.\n",
      "5        Mr.\n",
      "6        Mr.\n",
      "7    Master.\n",
      "8       Mrs.\n",
      "9       Mrs.\n",
      "Name: Title, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/ipykernel/__main__.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_test['Gender']=4\n",
    "data_test['Gender'] = data_test['Sex'].map( {'female':1, 'male':0}).astype(int)\n",
    "data_test['AgeFill']=data_test['Age']\n",
    "\n",
    "##title\n",
    "\n",
    "data_test['Title']=data_test['Name'].str.split(',').str.get(1).str.split().str.get(0)\n",
    "data_test.loc[(data_test['Title']=='Mlle.') ,'Title']=\"Miss.\"\n",
    "data_test.loc[(data_test['Title']==\"Mme.\") ,'Title']=\"Mrs.\"\n",
    "data_test.loc[(data_test['Title']==\"Ms.\") ,'Title']=\"Mrs.\"\n",
    "\n",
    "data_test['Rare']=data_test['Title'].isin([\"Master.\", \"Miss.\", \"Mrs.\", \"Mr.\"])\n",
    "\n",
    "data_test.loc[(data_test['Rare']==False),'Title']=\"Other\"\n",
    "\n",
    "#mother variable\n",
    "data_test['Mother']=0\n",
    "data_test.loc[((data_test['Title']==\"Mrs.\")&(data_test['Parch']>0)),'Mother']=1\n",
    "\n",
    "data_test = data_test.drop(['Rare'], axis = 1)\n",
    "#data_test['Title']=le_name.fit_transform(data_test['Title'])\n",
    "\n",
    "#fill in median of master for those with missing values \n",
    "data_test.loc[(data_test['Title']=='Master')& (data_test.Age.isnull()),'AgeFill']=data_test[data_test['Title']=='Master']['Age'].dropna().median()\n",
    "\n",
    "\n",
    "\n",
    "#Family Size\n",
    "data_test['FamilySize']=data_test['SibSp']+data['Parch']+1\n",
    "\n",
    "\n",
    "#Fare\n",
    "data_test['Fare']=data_test['Fare']/data_test['FamilySize']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#fill in missing ages and fares.\n",
    "\n",
    "median_fare = np.zeros((2,3))\n",
    "median_ages = np.zeros((2,3))\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_fare[i,j] = data_test[(data_test['Gender'] == i ) & (data_test['Pclass'] ==j+1)]['Fare'].dropna().median()\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata_test.loc[ (data_test.Fare.isnull() & (data_test['Gender']==i) & (data_test['Pclass']==j+1)), 'Fare']=median_fare[i,j]\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_ages[i,j] = data_test[(data_test['Gender'] == i ) & (data_test['Pclass'] ==j+1)]['Age'].dropna().median()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata_test.loc[ (data_test.Age.isnull() & (data_test['Gender']==i) & (data_test['Pclass']==j+1)), 'AgeFill']=median_ages[i,j]\n",
    "\n",
    "        \n",
    "data_test['Fare2']=2\n",
    "data_test.loc[(data_test['Fare']<10),'Fare2']=1\n",
    "data_test.loc[(data_test['Fare']>40),'Fare2']=3\n",
    "\n",
    "#Normalize data for fare\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "data_test['Fare']=scale(data_test['Fare'])\n",
    "\n",
    "\n",
    "#Embarked\n",
    "data_test['Embarked']=data_test['Embarked'].fillna(\"S\")\n",
    "data_test['Embarked'][data_test['Embarked']==\"S\"]=0\n",
    "data_test['Embarked'][data_test['Embarked']==\"C\"]=1\n",
    "data_test['Embarked'][data_test['Embarked']==\"Q\"]=2\n",
    "\n",
    "\n",
    "#Ticket\n",
    "data_test['Tix']=data_test['Ticket'].str.split().str.get(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print data[\"Title\"].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "Gender         891 non-null int64\n",
      "Title          891 non-null int64\n",
      "Mother         891 non-null int64\n",
      "FamilySize     891 non-null int64\n",
      "Fare2          891 non-null int64\n",
      "AgeFill        891 non-null float64\n",
      "dtypes: float64(3), int64(10), object(5)\n",
      "memory usage: 125.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "Gender         418 non-null int64\n",
      "AgeFill        418 non-null float64\n",
      "Title          418 non-null int64\n",
      "Mother         418 non-null int64\n",
      "FamilySize     418 non-null float64\n",
      "Fare2          418 non-null int64\n",
      "Tix            418 non-null object\n",
      "dtypes: float64(4), int64(8), object(6)\n",
      "memory usage: 58.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2652: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#encode labels for tix & title\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "l_e1 = LabelBinarizer()\n",
    "l_e2 = LabelEncoder()\n",
    "\n",
    "\n",
    "#data[\"Tix\"] = l_e1.fit_transform(data[\"Tix\"])\n",
    "\n",
    "\n",
    "#data_test[\"Tix\"] = l_e1.transform(data_test[\"Tix\"])\n",
    "\n",
    "data[\"Title\"] = l_e2.fit_transform(data[\"Title\"])\n",
    "data_test[\"Title\"] = l_e2.transform(data_test[\"Title\"])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot = OneHotEncoder()\n",
    "data_cat = pandas.DataFrame(one_hot.fit_transform(data[['Title','Embarked']]).toarray())\n",
    "data_test_cat = pandas.DataFrame(one_hot.transform(data_test[['Title','Embarked']]).toarray())\n",
    "\n",
    "data.info()\n",
    "data_test.info()\n",
    "#print data_cat.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unused columns for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dropping variables from data\n",
    "\n",
    "#data = data.drop(['Name', 'Age', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Agemissing'], axis = 1)\n",
    "#data = data.drop(['PassengerId'], axis = 1)\n",
    "\n",
    "#print data.describe()\n",
    "\n",
    "\n",
    "data2 = data[[\"Pclass\",\"AgeFill\",\"Gender\",\"Fare\",\"Parch\",\"SibSp\"]]\n",
    "data3 = np.hstack((data[[\"Gender\",\"Pclass\",\"Fare\",\"FamilySize\",\"Parch\",'AgeFill']],data_cat))\n",
    "target = data[\"Survived\"]\n",
    "\n",
    "#one hot encoder \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dropping variables from data_test\n",
    "#data_test = data_test.drop(['Name', 'Age', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Agemissing'], axis = 1)\n",
    "\n",
    "#print data_test.describe()\n",
    "\n",
    "list_to_write = data_test['PassengerId']\n",
    "list_to_write = list_to_write.values \n",
    "\n",
    "#data_test = data_test.drop(['PassengerId'], axis = 1)\n",
    "\n",
    "test_data2 = data_test[[\"Pclass\",\"AgeFill\",\"Gender\",\"Fare\",\"Parch\",\"SibSp\"]]\n",
    "test_data3 = np.hstack((data_test[[\"Gender\",\"Pclass\",\"Fare\",\"FamilySize\",\"Parch\",\"AgeFill\"]],data_test_cat))\n",
    "#print test_data3.info()\n",
    "#print data3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating separate validation and train datasets from the train data\n",
    "\n",
    "1. Basic splitting\n",
    "2. Through cross validation - SKIP\n",
    "3. Lasso??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plain splitting\n",
    "train_data, validation_data, train_target, valid_target = train_test_split(data3, target, test_size = 0.15)\n",
    "\n",
    "\n",
    "valid_data2=validation_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=2000, min_samples_split =25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#scaler = preprocessing.StandardScaler()\n",
    "#train_data = scaler.fit_transform(train_data)\n",
    "#validation_data = scaler.transform(validation_data)\n",
    "#test_data3 = scaler.transform(test_data3)\n",
    "\n",
    "#validation_data = validation_data.values\n",
    "#train_data=train_data.values\n",
    "\n",
    "#test_data3 = test_data3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clf.fit(train_data, train_target)\n",
    "pred = clf.predict(test_data3)\n",
    "predori = clf.predict(validation_data)\n",
    "predtrain = clf.predict(train_data)\n",
    "\n",
    "df = pandas.DataFrame(validation_data)\n",
    "\n",
    "\n",
    "#a = pandas.crosstab(predori, [valid_data2['Pclass'], valid_data2['Gender']])\n",
    "\n",
    "#b = pandas.crosstab(valid_data2['Survived'], [valid_data2['Pclass'], valid_data2['Gender']])\n",
    "\n",
    "#print a \n",
    "#print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.84328358209\n",
      "Train accuracy:  0.86393659181\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.86      0.88        86\n",
      "          1       0.76      0.81      0.79        48\n",
      "\n",
      "avg / total       0.85      0.84      0.84       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print accuracy and confusion matrix and save test predictions is csv file\n",
    "\n",
    "\n",
    "final = np.concatenate(([list_to_write], [pred]), axis = 0)\n",
    "\n",
    "\n",
    "#print final\n",
    "\n",
    "#print list_to_write\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(predori, valid_target)\n",
    "print \"Validation Accuracy: \", acc\n",
    "\n",
    "acc2 = accuracy_score(predtrain, train_target)\n",
    "print \"Train accuracy: \", acc2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(valid_target, predori, labels=None,target_names=None,))\n",
    "#header = \"PassengerId, Survived\"\n",
    "#np.set_printoptions(suppress = True)\n",
    "np.savetxt(\"mydata.csv\", np.transpose(final), delimiter= \",\", fmt = '%.1i',comments='',header = \"PassengerId,Survived\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18659247  0.10830486  0.15883272  0.06243939  0.01702729  0.09236447\n",
      "  0.01472819  0.04593415  0.21120889  0.05976604  0.00721543  0.01501366\n",
      "  0.01178164  0.00879081]\n"
     ]
    }
   ],
   "source": [
    "#print model scores for each variable\n",
    "\n",
    "print clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
