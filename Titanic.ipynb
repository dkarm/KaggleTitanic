{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to import all the modules used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv as csv\n",
    "import numpy as np\n",
    "import pandas\n",
    "from ggplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to import both the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#load in csv file train data\n",
    "data = pandas.read_csv('train.csv', header = 0)\n",
    "\n",
    "#load in csv file test data\n",
    "data_test = pandas.read_csv('test.csv', header = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory analysis on train data - not to be used when running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PassengerId        Pclass          Name           Age         SibSp  \\\n",
      "Survived           0      1      0      1      0      1      0      1      0   \n",
      "Sex                                                                            \n",
      "female          81.0  233.0   81.0  233.0   81.0  233.0   81.0  233.0   81.0   \n",
      "male           468.0  109.0  468.0  109.0  468.0  109.0  468.0  109.0  468.0   \n",
      "\n",
      "                 Parch        Ticket          Fare         Cabin         \\\n",
      "Survived      1      0      1      0      1      0      1      0      1   \n",
      "Sex                                                                       \n",
      "female    233.0   81.0  233.0   81.0  233.0   81.0  233.0   81.0  233.0   \n",
      "male      109.0  468.0  109.0  468.0  109.0  468.0  109.0  468.0  109.0   \n",
      "\n",
      "         Embarked         \n",
      "Survived        0      1  \n",
      "Sex                       \n",
      "female       81.0  233.0  \n",
      "male        468.0  109.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "table = pandas.DataFrame.pivot_table(data, index = ['Sex'], columns = 'Survived', aggfunc = np.size)\n",
    "\n",
    "print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diptikarmarkar/tensorflow/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
       "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
       "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering Part 1:\n",
    "Change some of the string variables to numerical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 22 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "Gender         891 non-null int64\n",
      "AgeFill        891 non-null float64\n",
      "Agemissing     891 non-null int64\n",
      "FamilySize     891 non-null int64\n",
      "Embarked2      891 non-null int64\n",
      "Agebuckets     891 non-null int64\n",
      "Singlewomen    891 non-null int64\n",
      "menHigh        891 non-null int64\n",
      "Singlemen      891 non-null int64\n",
      "Fare2          891 non-null int64\n",
      "dtypes: float64(3), int64(14), object(5)\n",
      "memory usage: 153.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AgeFill</th>\n",
       "      <th>Agemissing</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Embarked2</th>\n",
       "      <th>Agebuckets</th>\n",
       "      <th>Singlewomen</th>\n",
       "      <th>menHigh</th>\n",
       "      <th>Singlemen</th>\n",
       "      <th>Fare2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>0.352413</td>\n",
       "      <td>29.112424</td>\n",
       "      <td>0.198653</td>\n",
       "      <td>0.904602</td>\n",
       "      <td>2.536476</td>\n",
       "      <td>1.984287</td>\n",
       "      <td>0.120090</td>\n",
       "      <td>0.136925</td>\n",
       "      <td>0.408530</td>\n",
       "      <td>1.820426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.304424</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>1.613459</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>0.399128</td>\n",
       "      <td>0.325249</td>\n",
       "      <td>0.343961</td>\n",
       "      <td>0.491838</td>\n",
       "      <td>0.736884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000         NaN    0.000000   \n",
       "50%     446.000000    0.000000    3.000000         NaN    0.000000   \n",
       "75%     668.500000    1.000000    3.000000         NaN    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare      Gender     AgeFill  Agemissing  FamilySize  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.381594   32.204208    0.352413   29.112424    0.198653    0.904602   \n",
       "std      0.806057   49.693429    0.477990   13.304424    0.399210    1.613459   \n",
       "min      0.000000    0.000000    0.000000    0.420000    0.000000    0.000000   \n",
       "25%      0.000000    7.910400    0.000000   21.500000    0.000000    0.000000   \n",
       "50%      0.000000   14.454200    0.000000   26.000000    0.000000    0.000000   \n",
       "75%      0.000000   31.000000    1.000000   36.000000    0.000000    1.000000   \n",
       "max      6.000000  512.329200    1.000000   80.000000    1.000000   10.000000   \n",
       "\n",
       "        Embarked2  Agebuckets  Singlewomen     menHigh   Singlemen       Fare2  \n",
       "count  891.000000  891.000000   891.000000  891.000000  891.000000  891.000000  \n",
       "mean     2.536476    1.984287     0.120090    0.136925    0.408530    1.820426  \n",
       "std      0.791503    0.399128     0.325249    0.343961    0.491838    0.736884  \n",
       "min      1.000000    1.000000     0.000000    0.000000    0.000000    1.000000  \n",
       "25%      2.000000    2.000000     0.000000    0.000000    0.000000    1.000000  \n",
       "50%      3.000000    2.000000     0.000000    0.000000    0.000000    2.000000  \n",
       "75%      3.000000    2.000000     0.000000    0.000000    1.000000    2.000000  \n",
       "max      3.000000    3.000000     1.000000    1.000000    1.000000    3.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the Sex variable to Gender\n",
    "data['Gender']=4\n",
    "data['Gender'] = data['Sex'].map( {'female':1, 'male':0}).astype(int)\n",
    "\n",
    "#Fill in missing ages and call AgeFill\n",
    "data['AgeFill']=data['Age']\n",
    "median_ages = np.zeros((2,3))\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_ages[i,j] = data[(data['Gender'] == i ) & (data['Pclass'] ==j+1)]['Age'].dropna().median()\n",
    "\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata.loc[ (data.Age.isnull() & (data['Gender']==i) & (data['Pclass']==j+1)), 'AgeFill']=median_ages[i,j]\n",
    "\n",
    "#print data[data['Age'].isnull()][['Gender', 'Pclass', 'AgeFill', 'Age']].head(10)\n",
    "\n",
    "data['Agemissing']=pandas.isnull(data.Age).astype(int)\n",
    "\n",
    "data['FamilySize'] = data['Parch'] + data['SibSp']\n",
    "\n",
    "#data.loc(data.Embarked.isnull(), data['Embarked'])='S'\n",
    "\n",
    "data['Embarked2'] = data['Embarked'].map( {'C':1, 'Q':2, 'S':3, None:3})\n",
    "\n",
    "data['Agebuckets'] = 2\n",
    "data.loc[ (data['AgeFill']<15) ,'Agebuckets']=1\n",
    "data.loc[ (data['AgeFill']>50) ,'Agebuckets']=3\n",
    "\n",
    "data['Singlewomen']=0\n",
    "data.loc[((data['AgeFill']>20)&(data['FamilySize']==0)&(data['Gender']==1)),'Singlewomen']=1\n",
    "\n",
    "data['menHigh']=0\n",
    "data.loc[((data['Pclass']==1)&(data['Gender']==0)),'menHigh']=1\n",
    "\n",
    "data['Singlemen']=0\n",
    "data.loc[((data['AgeFill']>20)&(data['FamilySize']==0)&(data['Gender']==0)),'Singlemen']=1\n",
    "\n",
    "data['Fare2']=2\n",
    "data.loc[(data['Fare']<10),'Fare2']=1\n",
    "data.loc[(data['Fare']>40),'Fare2']=3\n",
    "print data.info()\n",
    "\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>436</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived    0    1\n",
       "Title             \n",
       "0          17   23\n",
       "1          55  129\n",
       "2         436   81\n",
       "3          26  101\n",
       "4          15    8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #create new variables for family name and create a variable that predicts whether the family survived or not \n",
    "    #clued in as 1 if anyone from the family died\n",
    "\n",
    "\n",
    "    #create a Last Name column of data\n",
    "    #data['LastName']=data['Name'].str.split(',').str.get(0)\n",
    "\n",
    "    le_name = LabelEncoder()\n",
    "    #data['LastName'] = le_name.fit_transform(data['LastName'])\n",
    "\n",
    "    data.describe()\n",
    "\n",
    "    data['Title']=data['Name'].str.split(',').str.get(1).str.split().str.get(0)\n",
    "    data.loc[(data['Title']=='Mlle.') ,'Title']=\"Miss.\"\n",
    "    data.loc[(data['Title']==\"Mme.\") ,'Title']=\"Mrs.\"\n",
    "    data.loc[(data['Title']==\"Ms.\") ,'Title']=\"Mrs.\"\n",
    "\n",
    "    data['Rare']=data['Title'].isin([\"Master.\", \"Miss.\", \"Mrs.\", \"Mr.\"])\n",
    "\n",
    "    data.loc[(data['Rare']==False),'Title']=\"Other\"\n",
    "    data = data.drop(['Rare'], axis = 1)\n",
    "\n",
    "    data['Mother']=0\n",
    "    data.loc[((data['Title']==\"Mrs.\")&(data['Parch']>0)),'Mother']=1\n",
    "\n",
    "    data['Title']=le_name.fit_transform(data['Title'])\n",
    "\n",
    "    pandas.crosstab(data['Survived'], data['Title']).transpose()\n",
    "\n",
    "    #classify survival by family type\n",
    "    #pandas.crosstab(data['Survived'], data['LastName']).transpose()\n",
    "\n",
    "    #family_died = np.zeros((2,len(data['LastName'])))\n",
    "\n",
    "    #for i in range(0,len(data['LastName'])):\n",
    "     #   family_died[0,i]=data[(data['LastName']==i)]['Survived'].sum()\n",
    "\n",
    "    #for i in range(0,len(data['LastName'])):\n",
    "     #   if family_died[0,i]==0:\n",
    "      #      family_died[1,i]=1\n",
    "\n",
    "    #print family_died.transpose()[10]\n",
    "    #pandas.crosstab(data['Survived'], data['LastName']).transpose()\n",
    "\n",
    "    #data['FamilyDied']=0\n",
    "    #for i in range(0,len(data['LastName'])):\n",
    "     #   data.loc[(data['LastName']==i),'FamilyDied']=family_died[1,i]\n",
    "\n",
    "    #data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data,aes(x='Age',y='PassengerId',color ='Survived'))+ geom_point() +facet_grid('Sex') +\\\n",
    "    scale_color_brewer(type='diverging', palette=4) +xlab(\"Age\") + ylab(\"PassengerId\") + ggtitle(\"Age and Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Is survival linked to port of embarkment or class?\n",
    "\n",
    "Survival was worst for embarked S and for class 3. These were most likely the poor individuals. The women who perished seem to have come from the 'S' embarkment. \n",
    "\n",
    "Is survival linked to family size?\n",
    "\n",
    "It looks like men were travelling alone or those with larger families both perished more. Women who were travelling alone tended to survive more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data,aes(x='Pclass',y='PassengerId',color ='Survived'))+ geom_point()  +\\\n",
    "    scale_color_brewer(type='diverging', palette=4) +xlab(\"Pclass\") + ylab(\"PassengerId\") + ggtitle(\"Survival Rates by Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data,aes(x='Embarked2',y='PassengerId',color ='Survived'))+ geom_point()  +\\\n",
    "    scale_color_brewer(type='diverging', palette=4) +xlab(\"Embarked2\") + ylab(\"PassengerId\") + ggtitle(\"Survival Rates by Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data,aes(x='Embarked2',y='PassengerId',color ='Survived'))+ geom_point() + facet_grid(\"Sex\")+\\\n",
    "    scale_color_brewer(type='diverging', palette=4) +xlab(\"Embarked2\") + ylab(\"PassengerId\") + ggtitle(\"Survival Rates by Embarked and Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ggplot(data,aes(x='FamilySize',y='PassengerId',color ='Survived'))+ geom_point() +facet_grid(\"Sex\")+\\\n",
    "    scale_color_brewer(type='diverging', palette=4) +xlab(\"FamilySize\") + ylab(\"PassengerId\") + ggtitle(\"Survival Rates by Family Size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering for the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 21 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "Gender         418 non-null int64\n",
      "AgeFill        418 non-null float64\n",
      "Agemissing     418 non-null int64\n",
      "FamilySize     418 non-null int64\n",
      "Embarked2      418 non-null int64\n",
      "Agebuckets     418 non-null int64\n",
      "Singlewomen    418 non-null int64\n",
      "menHigh        418 non-null int64\n",
      "Singlemen      418 non-null int64\n",
      "Fare2          418 non-null int64\n",
      "dtypes: float64(3), int64(13), object(5)\n",
      "memory usage: 68.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_test['Gender']=4\n",
    "data_test['Gender'] = data_test['Sex'].map( {'female':1, 'male':0}).astype(int)\n",
    "data_test['AgeFill']=data_test['Age']\n",
    "\n",
    "median_fare = np.zeros((2,3))\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tmedian_fare[i,j] = data_test[(data_test['Gender'] == i ) & (data_test['Pclass'] ==j+1)]['Fare'].dropna().median()\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata_test.loc[ (data_test.Fare.isnull() & (data_test['Gender']==i) & (data_test['Pclass']==j+1)), 'Fare']=median_fare[i,j]\n",
    "\n",
    "for i in range(0,2):\n",
    "\tfor j in range(0,3):\n",
    "\t\tdata_test.loc[ (data_test.Age.isnull() & (data_test['Gender']==i) & (data_test['Pclass']==j+1)), 'AgeFill']=median_ages[i,j]\n",
    "\n",
    "data_test['Agemissing']=pandas.isnull(data_test.Age).astype(int)\n",
    "\n",
    "data_test['FamilySize'] = data_test['Parch'] + data_test['SibSp']\n",
    "\n",
    "#data_test.loc(data.Embarked.isnull(), 'Embarked')='S'\n",
    "\n",
    "data_test['Embarked2'] = data_test['Embarked'].map( {'C':1, 'Q':2, 'S':3, None:3})\n",
    "\n",
    "data_test['Agebuckets'] = 2\n",
    "data_test.loc[(data_test['AgeFill']<15),'Agebuckets']=1\n",
    "data_test.loc[(data_test['AgeFill']>50),'Agebuckets']=3\n",
    "\n",
    "data_test['Singlewomen']=0\n",
    "data_test.loc[((data_test['AgeFill']>20)&(data_test['FamilySize']==0)&(data_test['Gender']==1)),'Singlewomen']=1\n",
    "\n",
    "data_test['menHigh']=0\n",
    "data_test.loc[((data_test['Pclass']==1)&(data['Gender']==0)),'menHigh']=1\n",
    "\n",
    "data_test['Singlemen']=0\n",
    "data_test.loc[((data_test['AgeFill']>20)&(data_test['FamilySize']==0)&(data_test['Gender']==0)),'Singlemen']=1\n",
    "\n",
    "data_test['Fare2']=2\n",
    "data_test.loc[(data_test['Fare']<10),'Fare2']=1\n",
    "data_test.loc[(data_test['Fare']>40),'Fare2']=3\n",
    "print data_test.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 23 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "Gender         418 non-null int64\n",
      "AgeFill        418 non-null float64\n",
      "Agemissing     418 non-null int64\n",
      "FamilySize     418 non-null int64\n",
      "Embarked2      418 non-null int64\n",
      "Agebuckets     418 non-null int64\n",
      "Singlewomen    418 non-null int64\n",
      "menHigh        418 non-null int64\n",
      "Singlemen      418 non-null int64\n",
      "Fare2          418 non-null int64\n",
      "Title          418 non-null int64\n",
      "Mother         418 non-null int64\n",
      "dtypes: float64(3), int64(15), object(5)\n",
      "memory usage: 75.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#additional feature engineering for the test data set\n",
    "\n",
    "#create new variables for family name and create a variable that predicts whether the family survived or not \n",
    "#clued in as 1 if anyone from the family died\n",
    "\n",
    "\n",
    "#create a Last Name column of data\n",
    "#data_test['LastName']=data_test['Name'].str.split(',').str.get(0)\n",
    "\n",
    "#le_name = LabelEncoder()\n",
    "#data_test['LastName'] = le_name.transform(data_test['LastName'])\n",
    "\n",
    "#data.describe()\n",
    "#classify survival by family type\n",
    "#pandas.crosstab(data['Survived'], data['LastName']).transpose()\n",
    "\n",
    "data_test['Title']=data_test['Name'].str.split(',').str.get(1).str.split().str.get(0)\n",
    "data_test.loc[(data_test['Title']=='Mlle.') ,'Title']=\"Miss.\"\n",
    "data_test.loc[(data_test['Title']==\"Mme.\") ,'Title']=\"Mrs.\"\n",
    "data_test.loc[(data_test['Title']==\"Ms.\") ,'Title']=\"Mrs.\"\n",
    "\n",
    "data_test['Rare']=data_test['Title'].isin([\"Master.\", \"Miss.\", \"Mrs.\", \"Mr.\"])\n",
    "\n",
    "data_test.loc[(data_test['Rare']==False),'Title']=\"Other\"\n",
    "\n",
    "#mother variable\n",
    "data_test['Mother']=0\n",
    "data_test.loc[((data_test['Title']==\"Mrs.\")&(data_test['Parch']>0)),'Mother']=1\n",
    "\n",
    "data_test = data_test.drop(['Rare'], axis = 1)\n",
    "data_test['Title']=le_name.fit_transform(data_test['Title'])\n",
    "\n",
    "\n",
    "\n",
    "data_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unused columns for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Survived      Pclass      Gender  FamilySize   Embarked2  Agebuckets  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.383838    2.308642    0.352413    0.904602    2.536476    1.984287   \n",
      "std      0.486592    0.836071    0.477990    1.613459    0.791503    0.399128   \n",
      "min      0.000000    1.000000    0.000000    0.000000    1.000000    1.000000   \n",
      "25%      0.000000    2.000000    0.000000    0.000000    2.000000    2.000000   \n",
      "50%      0.000000    3.000000    0.000000    0.000000    3.000000    2.000000   \n",
      "75%      1.000000    3.000000    1.000000    1.000000    3.000000    2.000000   \n",
      "max      1.000000    3.000000    1.000000   10.000000    3.000000    3.000000   \n",
      "\n",
      "       Singlewomen     menHigh   Singlemen       Fare2       Title      Mother  \n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
      "mean      0.120090    0.136925    0.408530    1.820426    1.897868    0.062851  \n",
      "std       0.325249    0.343961    0.491838    0.736884    0.788759    0.242831  \n",
      "min       0.000000    0.000000    0.000000    1.000000    0.000000    0.000000  \n",
      "25%       0.000000    0.000000    0.000000    1.000000    1.000000    0.000000  \n",
      "50%       0.000000    0.000000    0.000000    2.000000    2.000000    0.000000  \n",
      "75%       0.000000    0.000000    1.000000    2.000000    2.000000    0.000000  \n",
      "max       1.000000    1.000000    1.000000    3.000000    4.000000    1.000000  \n",
      "         Survived      Pclass      Gender  FamilySize   Embarked2  Agebuckets  \\\n",
      "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
      "mean     0.383838    2.308642    0.352413    0.904602    2.536476    1.984287   \n",
      "std      0.486592    0.836071    0.477990    1.613459    0.791503    0.399128   \n",
      "min      0.000000    1.000000    0.000000    0.000000    1.000000    1.000000   \n",
      "25%      0.000000    2.000000    0.000000    0.000000    2.000000    2.000000   \n",
      "50%      0.000000    3.000000    0.000000    0.000000    3.000000    2.000000   \n",
      "75%      1.000000    3.000000    1.000000    1.000000    3.000000    2.000000   \n",
      "max      1.000000    3.000000    1.000000   10.000000    3.000000    3.000000   \n",
      "\n",
      "       Singlewomen     menHigh   Singlemen       Fare2       Title      Mother  \n",
      "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
      "mean      0.120090    0.136925    0.408530    1.820426    1.897868    0.062851  \n",
      "std       0.325249    0.343961    0.491838    0.736884    0.788759    0.242831  \n",
      "min       0.000000    0.000000    0.000000    1.000000    0.000000    0.000000  \n",
      "25%       0.000000    0.000000    0.000000    1.000000    1.000000    0.000000  \n",
      "50%       0.000000    0.000000    0.000000    2.000000    2.000000    0.000000  \n",
      "75%       0.000000    0.000000    1.000000    2.000000    2.000000    0.000000  \n",
      "max       1.000000    1.000000    1.000000    3.000000    4.000000    1.000000  \n",
      "       PassengerId      Pclass      Gender  FamilySize   Embarked2  \\\n",
      "count   418.000000  418.000000  418.000000  418.000000  418.000000   \n",
      "mean   1100.500000    2.265550    0.363636    0.839713    2.401914   \n",
      "std     120.810458    0.841838    0.481622    1.519072    0.854496   \n",
      "min     892.000000    1.000000    0.000000    0.000000    1.000000   \n",
      "25%     996.250000    1.000000    0.000000    0.000000    2.000000   \n",
      "50%    1100.500000    3.000000    0.000000    0.000000    3.000000   \n",
      "75%    1204.750000    3.000000    1.000000    1.000000    3.000000   \n",
      "max    1309.000000    3.000000    1.000000   10.000000    3.000000   \n",
      "\n",
      "       Agebuckets  Singlewomen     menHigh   Singlemen       Fare2  \\\n",
      "count  418.000000   418.000000  418.000000  418.000000  418.000000   \n",
      "mean     2.000000     0.136364    0.169856    0.401914    1.837321   \n",
      "std      0.385592     0.343586    0.375957    0.490872    0.747398   \n",
      "min      1.000000     0.000000    0.000000    0.000000    1.000000   \n",
      "25%      2.000000     0.000000    0.000000    0.000000    1.000000   \n",
      "50%      2.000000     0.000000    0.000000    0.000000    2.000000   \n",
      "75%      2.000000     0.000000    0.000000    1.000000    2.000000   \n",
      "max      3.000000     1.000000    1.000000    1.000000    3.000000   \n",
      "\n",
      "            Title      Mother  \n",
      "count  418.000000  418.000000  \n",
      "mean     1.916268    0.074163  \n",
      "std      0.783630    0.262349  \n",
      "min      0.000000    0.000000  \n",
      "25%      2.000000    0.000000  \n",
      "50%      2.000000    0.000000  \n",
      "75%      2.000000    0.000000  \n",
      "max      4.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "#dropping variables from data\n",
    "\n",
    "data = data.drop(['Name', 'Age', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Agemissing','AgeFill','Parch','SibSp', 'Fare'], axis = 1)\n",
    "data = data.drop(['PassengerId'], axis = 1)\n",
    "\n",
    "print data.describe()\n",
    "#data = data.values\n",
    "\n",
    "\n",
    "print data.describe()\n",
    "#dropping variables from data_test\n",
    "data_test = data_test.drop(['Name', 'Age', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Agemissing','AgeFill','Parch','SibSp','Fare'], axis = 1)\n",
    "\n",
    "print data_test.describe()\n",
    "\n",
    "list_to_write = data_test['PassengerId']\n",
    "list_to_write = list_to_write.values \n",
    "\n",
    "data_test = data_test.drop(['PassengerId'], axis = 1)\n",
    "\n",
    "data_test = data_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating separate validation and train datasets from the train data\n",
    "\n",
    "1. Basic splitting\n",
    "2. Through cross validation - SKIP\n",
    "3. Lasso??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plain splitting\n",
    "train_data, validation_data = train_test_split(data, test_size = 0.15)\n",
    "\n",
    "\n",
    "valid_data2=validation_data\n",
    "\n",
    "validation_data = validation_data.values\n",
    "train_data=train_data.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model Creation: \n",
    "    \n",
    "    1. RandomForestClassifier\n",
    "    \n",
    "    #through cross validation\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "kf = KFold(len(data['Gender']), n_folds = 4, shuffle = True)\n",
    "for train_indices, test_indices in kf:\n",
    "    train_data = [data[ii] for ii in train_indices]\n",
    "    validation_data = [data[ii] for ii in test_indices]\n",
    "    \n",
    "    #cross validation --  SKIP\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "kf = KFold(len(data['Gender']), n_folds = 4, shuffle = True)\n",
    "#for train_indices, test_indices in kf:\n",
    " #   train_data = [data[ii] for ii in train_indices]\n",
    "  # clf.fit(train_data[0::,1::], train_data[0::,0])\n",
    "    #predori = clf.predict(validation_data[0::,1::])\n",
    "   # predtrain = clf.predict(train_data[0::,1::])\n",
    "    \n",
    "d = cross_val_score(clf, train_data[0::,1::],train_data[0::,0],cv=kf, n_jobs=1)\n",
    "    \n",
    "    \n",
    "   2. \n",
    "   #Support Vector Machine\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C=0.8)\n",
    "\n",
    "\n",
    "3. ridge\n",
    "#Ridge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier(alpha = .001)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(min_samples_split = 5, warm_start=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clf.fit(train_data[0::,1::], train_data[0::,0])\n",
    "pred = clf.predict(data_test[0::,0::])\n",
    "predori = clf.predict(validation_data[0::,1::])\n",
    "predtrain = clf.predict(train_data[0::,1::])\n",
    "\n",
    "df = pandas.DataFrame(validation_data)\n",
    "\n",
    "\n",
    "#a = pandas.crosstab(predori, [valid_data2['Pclass'], valid_data2['Gender']])\n",
    "\n",
    "#b = pandas.crosstab(valid_data2['Survived'], [valid_data2['Pclass'], valid_data2['Gender']])\n",
    "\n",
    "#print a \n",
    "#print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.820895522388\n",
      "Train accuracy:  0.866578599736\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.87      0.86        87\n",
      "          1       0.76      0.72      0.74        47\n",
      "\n",
      "avg / total       0.82      0.82      0.82       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print accuracy and confusion matrix and save test predictions is csv file\n",
    "\n",
    "\n",
    "final = np.concatenate(([list_to_write], [pred]), axis = 0)\n",
    "\n",
    "\n",
    "#print final\n",
    "\n",
    "#print list_to_write\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(predori, validation_data[0::,0])\n",
    "print \"Validation Accuracy: \", acc\n",
    "\n",
    "acc2 = accuracy_score(predtrain, train_data[0::,0])\n",
    "print \"Train accuracy: \", acc2\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(validation_data[0::,0], predori, labels=None,target_names=None,))\n",
    "#header = \"PassengerId, Survived\"\n",
    "#np.set_printoptions(suppress = True)\n",
    "np.savetxt(\"mydata.csv\", np.transpose(final), delimiter= \",\", fmt = '%.1i',comments='',header = \"PassengerId,Survived\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print model scores for each variable\n",
    "\n",
    "print clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
